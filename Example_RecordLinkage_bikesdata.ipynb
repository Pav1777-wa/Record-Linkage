{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import recordlinkage\n",
    "from recordlinkage import preprocessing\n",
    "from recordlinkage.standardise import clean\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm, model_selection, preprocessing\n",
    "from recordlinkage.index import Full\n",
    "import sklearn\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4786, 10)\n",
      "      id                               bike_name city_posted  km_driven  \\\n",
      "0  36082  Royal Enfield Bullet Electra Twinspark       Delhi        900   \n",
      "1  36115           Royal Enfield Thunderbird 350      Mumbai      15000   \n",
      "2  36118                Royal Enfield Bullet 350      Mumbai      50000   \n",
      "3  36119                            KTM Duke 200      Mumbai      13000   \n",
      "4  36120              Yamaha YZF R15 Version 2.0      Mumbai      28000   \n",
      "\n",
      "   color fuel_type   price  model_year  owner_type                        url  \n",
      "0  black    Petrol  110000        2015  FirstOwner  http://www.bikedekho.com/  \n",
      "1  black    Petrol  110000        2013  FirstOwner  http://www.bikedekho.com/  \n",
      "2   grey    Petrol  110000        1984  FifthOwner  http://www.bikedekho.com/  \n",
      "3  white    Petrol  100000        2014  FirstOwner  http://www.bikedekho.com/  \n",
      "4    red    Petrol   70000        2013  FirstOwner  http://www.bikedekho.com/  \n",
      "id              int64\n",
      "bike_name      object\n",
      "city_posted    object\n",
      "km_driven       int64\n",
      "color          object\n",
      "fuel_type      object\n",
      "price           int64\n",
      "model_year      int64\n",
      "owner_type     object\n",
      "url            object\n",
      "dtype: object\n",
      "274\n"
     ]
    }
   ],
   "source": [
    " \n",
    " # Read the first file into pandas dataframe\n",
    " df1=pd.read_csv('bikedekho.csv')\n",
    " print(df1.shape) # total number of records in the file\n",
    " print(df1.head()) # to look at the first few rows\n",
    " print(df1.dtypes) # print the datatypes of all columns in the file\n",
    " print(df1['bike_name'].nunique())\n",
    " df1['bike_name']=clean(df1['bike_name']) #clean the string values in the bikename column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9003, 10)\n",
      "   id                            bike_name city_posted  km_driven  color  \\\n",
      "0  12   TVS Apache RTR 160 Rear Drum Brake      Mumbai      28500   grey   \n",
      "1  20              Bajaj Discover 125 Disc      Mumbai      21300  green   \n",
      "2  26              Bajaj Pulsar 150 DTS- i   Bangalore      20000  black   \n",
      "3  29  Royal Enfield Thunderbird Twinspark      Mumbai      20000  black   \n",
      "4  53                       Hero Karizma R      Mumbai      35000  black   \n",
      "\n",
      "  fuel_type  price  model_year owner_type  \\\n",
      "0    Petrol  40000        2010      First   \n",
      "1    Petrol  27000        2009      First   \n",
      "2    Petrol  70000        2010      First   \n",
      "3    Petrol  85000        2008      First   \n",
      "4    Petrol  45000        2007      First   \n",
      "\n",
      "                                                 url  \n",
      "0  http://www.bikewale.com/used/bikes-in-mumbai/t...  \n",
      "1  http://www.bikewale.com/used/bikes-in-mumbai/b...  \n",
      "2  http://www.bikewale.com/used/bikes-in-bangalor...  \n",
      "3  http://www.bikewale.com/used/bikes-in-mumbai/r...  \n",
      "4  http://www.bikewale.com/used/bikes-in-mumbai/h...  \n",
      "id              int64\n",
      "bike_name      object\n",
      "city_posted    object\n",
      "km_driven       int64\n",
      "color          object\n",
      "fuel_type      object\n",
      "price           int64\n",
      "model_year      int64\n",
      "owner_type     object\n",
      "url            object\n",
      "dtype: object\n",
      "437\n"
     ]
    }
   ],
   "source": [
    "# Now to look at the second file, read it into dataframe 2\n",
    "df2=pd.read_csv('bikewale.csv')\n",
    "print(df2.shape)   # get the total number of rows\n",
    "print(df2.head())  # print first few rows to get an idea of how our data looks like\n",
    "print(df2.dtypes)  # print the datatypes of each column\n",
    "print(df2['bike_name'].nunique())  # lets look at the number of unique values in the bike name column\n",
    "df2['bike_name']=clean(df2['bike_name']) # clean the string values in the bike name column using the \"clean\" library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 2)\n",
      "   ltable.id  rtable.id\n",
      "0      36442       1820\n",
      "1      36480      23151\n",
      "2      36480      27834\n",
      "3      36717      33756\n",
      "4      36734      11034\n",
      "400\n",
      "421\n",
      "(445, 12)\n",
      "   ltable.id  rtable.id     id               bike_name city_posted  km_driven  \\\n",
      "0      36442       1820  36442        Bajaj Pulsar 135       Delhi      17000   \n",
      "1      36480      23151  36480  Hero Honda Passion Pro       Delhi      10200   \n",
      "2      36480      27834  36480  Hero Honda Passion Pro       Delhi      10200   \n",
      "3      36717      33756  36717         Hero Honda Hunk       Delhi      33000   \n",
      "4      36734      11034  36734          Yamaha YZF R15       Delhi      17000   \n",
      "\n",
      "   color fuel_type  price  model_year   owner_type                        url  \n",
      "0    red    Petrol  27999        2010  SecondOwner  http://www.bikedekho.com/  \n",
      "1  black    Petrol  32000        2013   FirstOwner  http://www.bikedekho.com/  \n",
      "2  black    Petrol  32000        2013   FirstOwner  http://www.bikedekho.com/  \n",
      "3    red    Petrol  27000        2011  SecondOwner  http://www.bikedekho.com/  \n",
      "4    red    Petrol  46000        2011  SecondOwner  http://www.bikedekho.com/  \n",
      "Index(['ltable.id', 'rtable.id', 'id', 'bike_name', 'city_posted', 'km_driven',\n",
      "       'color', 'fuel_type', 'price', 'model_year', 'owner_type', 'url'],\n",
      "      dtype='object')\n",
      "(445, 12)\n",
      "   ltable.id  rtable.id     id                     bike_name city_posted  \\\n",
      "0      36442       1820   1820  Bajaj Pulsar 135 LS Standard       Delhi   \n",
      "1      36480      23151  23151   Hero Passion PRO Self Alloy       Delhi   \n",
      "2      36480      27834  27834   Hero Honda Karizma Standard       Delhi   \n",
      "3      42803      27834  27834   Hero Honda Karizma Standard       Delhi   \n",
      "4      36717      33756  33756  Hero Honda Passion Plus Drum       Delhi   \n",
      "\n",
      "   km_driven   color fuel_type  price  model_year owner_type  \\\n",
      "0      16000     red    Petrol  45000        2010      First   \n",
      "1       9500   black    Petrol  40000        2013      First   \n",
      "2      10000  yellow    Petrol  40000        2013      First   \n",
      "3      10000  yellow    Petrol  40000        2013      First   \n",
      "4      34000    blue    Petrol  31000        2011      First   \n",
      "\n",
      "                                                 url  \n",
      "0  http://www.bikewale.com/used/bikes-in-newdelhi...  \n",
      "1  http://www.bikewale.com/used/bikes-in-newdelhi...  \n",
      "2  http://www.bikewale.com/used/bikes-in-newdelhi...  \n",
      "3  http://www.bikewale.com/used/bikes-in-newdelhi...  \n",
      "4  http://www.bikewale.com/used/bikes-in-newdelhi...  \n",
      "Index(['ltable.id', 'rtable.id', 'id', 'bike_name', 'city_posted', 'km_driven',\n",
      "       'color', 'fuel_type', 'price', 'model_year', 'owner_type', 'url'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Until  now we have two files that we are going to link using the supervised classificatioin models. For that we also need\n",
    "# labled data set. Lets look at the true matches/links that we have:\n",
    "\n",
    "df1=pd.read_csv('labeled_data.csv',skiprows=5,usecols=[1,2])  # I am skipping first five rows just because there is glitch in\n",
    "#formatting of this file\n",
    "\n",
    "df1.columns= ['ltable.id','rtable.id']\n",
    "print(df1.shape)\n",
    "print(df1.head())\n",
    "\n",
    "#This file contains the id's of the true match pairs from the bikedekho.csv and bikewale.csv file. To see how many unique\n",
    "#records are there from each file since its possible that a record from FILE-1 has multiple links in the FILE-2 and vice versa\n",
    "\n",
    "print(df1['ltable.id'].nunique()) \n",
    "print(df1['rtable.id'].nunique())\n",
    "\n",
    "# Now we have id's of records from  both files , we need to get rest of the info for these records from their respective files\n",
    "\n",
    "df2=pd.read_csv('bikedekho.csv')\n",
    "# merge them on the ID's to get the rest of the columns from the df2\n",
    "df4=pd.merge(df1,df2,left_on=['ltable.id'],right_on=['id'])\n",
    "print(df4.shape) # print the number of records to make sure we are doing it right\n",
    "print(df4.head()) # have a look at first few rows\n",
    "print(df4.columns) # print the column names to make sure we are getting all of the columns\n",
    "\n",
    "# Writing the true links into a separate file    \n",
    "df4.to_csv('bikedekho_lable.csv',index=False)\n",
    "    \n",
    "# Repeat the same steps for 'bikewale.csv' file\n",
    "df3=pd.read_csv('bikewale.csv')\n",
    "df5=pd.merge(df1,df3,left_on=['rtable.id'],right_on=['id'])\n",
    "print(df5.shape)\n",
    "print(df5.head())\n",
    "print(df5.columns)\n",
    "df5.to_csv('bikewale_lable.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bike_name', 'city_posted', 'km_driven', 'color', 'fuel_type', 'price',\n",
      "       'model_year', 'owner_type', 'url'],\n",
      "      dtype='object')\n",
      "(421, 9)\n",
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n",
      "(168400,)\n"
     ]
    }
   ],
   "source": [
    "# now that we have these true matches into their own consecutive files, next step is to apply full indexing to get all possible pairs and comparing them using \n",
    "# different comparison methods to generate the similarity scores between them.\n",
    "\n",
    "df1=pd.read_csv('bikedekho_lable.csv',sep=',', usecols=[2,3,4,5,6,7,8,9,10,11])  # only using the columns that were used to generate the labeled data\n",
    "df1.set_index('id', inplace=True) # set id as index\n",
    "df1 = df1[~df1.index.duplicated(keep='first')] # remove any duplicate values \n",
    "\n",
    "\n",
    "# repeating the above three steps for the second file as well    \n",
    "df2=pd.read_csv('bikewale_lable.csv', sep=',', usecols=[2,3,4,5,6,7,8,9,10,11])\n",
    "df2.set_index('id', inplace=True)\n",
    "df2 = df2[~df2.index.duplicated(keep='first')]\n",
    "\n",
    "# A full index is an index with all possible combinations of record pairs. In case of linking, this indexation method generates the cartesian product of both DataFrame’s. \n",
    "indexer=recordlinkage.index.Full()\n",
    "pcl=indexer.index(df1,df2)\n",
    "print(pcl.shape)\n",
    "\n",
    "# We can also divide the pairs into chunks if we have some sort of memory issue, so that the processing will be done without any error\n",
    "\n",
    "x = recordlinkage.index_split(pcl, 1000)\n",
    "for chunk in x:\n",
    "    \n",
    "# for each chunk of 1000 we compare the attributes/features of the pairs to compute the similarity score between them.\n",
    "\n",
    "    compare_cl = recordlinkage.Compare()   \n",
    "\n",
    "# to compare the string type we are using the jarowinkler similarity. \n",
    "\n",
    "    compare_cl.string('bike_name', 'bike_name', method='jarowinkler', label='bikenameJW')\n",
    "    compare_cl.string('city_posted', 'city_posted', method='jarowinkler', label='citypostedJW')\n",
    "    compare_cl.string('color', 'color', method='jarowinkler', label='colorJW')\n",
    "    compare_cl.string('fuel_type', 'fuel_type', method='jarowinkler', label='fueltypeJW')\n",
    "        \n",
    "# to compare the integer type we are using the exact comparison where the function returns the value 1 if the values are totally similar otherwise it returns the value 0.\n",
    "    compare_cl.exact('km_driven', 'km_driven', label='km_driven')\n",
    "    compare_cl.exact('price', 'price', label='price')\n",
    "    compare_cl.exact('model_year', 'model_year', label='model_year')\n",
    "    \n",
    "    features = compare_cl.compute(chunk, df1, df2)  # Compare the records of each record pair. Calling this method starts the comparing of records.\n",
    "       \n",
    "    with open('labelFeature.csv', 'a') as f:    # the feature vectors computed for the pairs are written into this file.\n",
    "            features.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ltable.id  rtable.id  gold\n",
      "0      36217      28620     0\n",
      "1      36219      31966     0\n",
      "2      36224      24610     1\n",
      "3      36243      22741     0\n",
      "4      36245      29302     1\n",
      "(130, 3)\n",
      "(320, 3)\n",
      "(130, 13)\n",
      "(319, 13)\n",
      "(449, 13)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('labelFeature.csv')\n",
    "df1=pd.read_csv('labeled_data.csv',usecols=[1,2,13])\n",
    "print(df1.head())\n",
    "# getting the matches and non-matchces into separate files to extract their features from df\n",
    "df2=df1[df1['gold']==1]\n",
    "print(df2.shape)\n",
    "df3=df1[df1['gold']==0]\n",
    "print(df3.shape)\n",
    "df4=pd.merge(df,df2,left_on=['lID','rID'],right_on=['ltable.id','rtable.id'])\n",
    "print(df4.shape)\n",
    "df5=pd.merge(df,df3,left_on=['lID','rID'],right_on=['ltable.id','rtable.id'])\n",
    "print(df5.shape)\n",
    "df6 = pd.concat([df4, df5])\n",
    "print(df6.shape)\n",
    "df6.to_csv('Finaltrain.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150  12]\n",
      " [  7  56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       162\n",
      "           1       0.82      0.89      0.85        63\n",
      "\n",
      "    accuracy                           0.92       225\n",
      "   macro avg       0.89      0.91      0.90       225\n",
      "weighted avg       0.92      0.92      0.92       225\n",
      "\n",
      "Accuracy: 0.9155555555555556\n"
     ]
    }
   ],
   "source": [
    "# Lets train our Random Forest and Support Vector Machine Classifiers\n",
    "df1=pd.read_csv('Finaltrain.csv')\n",
    "X=df1.drop('gold',axis=1)\n",
    "\n",
    "y=df1['gold']\n",
    "\n",
    "# dividing our train data into train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "clf=RandomForestClassifier(n_estimators=100,max_features='sqrt',max_depth=200,min_samples_leaf=2,min_samples_split=6,bootstrap=False)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
